<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Capture and Analysis</title>
</head>
<body>
    <button id="start">Start Listening</button>
    <script type="module">
        import AudioProcessor from './index.js'
        document.getElementById('start').addEventListener('click', async () => {
          const a = new AudioProcessor()
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                const analyser = audioContext.createAnalyser();

                source.connect(analyser);
                analyser.fftSize = 32768; // Or whatever size you need

                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                const draw = () => {
                    requestAnimationFrame(draw);

                    analyser.getByteFrequencyData(dataArray);

                    This is where the magic happens, but be careful what you log...
                    console.log({
                      energy: a.energy(dataArray),
                      spectralCentroid: a.spectralCentroid(dataArray)
                    });
                    // console.log(a.spectralCentroid(dataArray).value);
                };

                draw();
            } catch (error) {
                console.error('Something went wrong:', error);
            }
        });
    </script>
</body>
</html>
